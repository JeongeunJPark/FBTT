{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 58스텝 : VGG 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![그림](./Posting3/VGG구조.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3*3 커널 크기, 출력층 64개       \n",
    "- 풀링\n",
    "- 3*3 커널 크기, 출력층 128개  \n",
    "- 풀링\n",
    "- 3*3 커널 크기, 출력층 256개     \n",
    "- 풀링           \n",
    "- 3*3 커널 크기, 출력층 512개         \n",
    "- 풀링           \n",
    "- 3*3 커널 크기, 출력층 512개      \n",
    "- 풀링    \n",
    "- 리니어 \n",
    "- 드롭아웃        \n",
    "- 리니어\n",
    "- 드롭아웃      \n",
    "- 리니어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 3*3 합성곱층 사용         \n",
    "> - 풀링 하면 2배로 증가      \n",
    "> - 완전 연결 계층에서는 드롭아웃 사용       \n",
    "> - 활성화 함수로는 ReLU 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dezero.function as F\n",
    "import dezero.layers as L\n",
    "\n",
    "#모델 클래스를 상속받아 사용함\n",
    "class VGG16(Model):\n",
    "    def __init__(self):\n",
    "        \n",
    "        #부모 클래스의 이닛을 물려받아 사용\n",
    "        super().__init__() \n",
    "        \n",
    "        self.conv1_1 = L.Conv2d(64,kernel_size=3, stride=1, pad=1)\n",
    "        self.conv1_2 = L.Conv2d(64,kernel_size=3, stride=1, pad=1)\n",
    "        \n",
    "        self.conv2_1 = L.Conv2d(128,kernel_size=3, stride=1, pad=1)\n",
    "        self.conv2_2 = L.Conv2d(128,kernel_size=3, stride=1, pad=1)\n",
    "        \n",
    "        self.conv3_1 = L.Conv2d(256,kernel_size=3, stride=1, pad=1)\n",
    "        self.conv3_2 = L.Conv2d(256,kernel_size=3, stride=1, pad=1)\n",
    "        self.conv3_3 = L.Conv2d(256,kernel_size=3, stride=1, pad=1)\n",
    "        \n",
    "        self.conv4_1 = L.Conv2d(512,kernel_size=3, stride=1, pad=1)\n",
    "        self.conv4_2 = L.Conv2d(512,kernel_size=3, stride=1, pad=1)\n",
    "        self.conv4_3 = L.Conv2d(512,kernel_size=3, stride=1, pad=1)\n",
    "        \n",
    "        self.conv5_1 = L.Conv2d(512,kernel_size=3, stride=1, pad=1)\n",
    "        self.conv5_2 = L.Conv2d(512,kernel_size=3, stride=1, pad=1)\n",
    "        self.conv5_3 = L.Conv2d(512,kernel_size=3, stride=1, pad=1)\n",
    "        \n",
    "        self.fc6 = L.Linear(4096)\n",
    "        self.fc7 = L.Linear(4096)\n",
    "        self.fc8 = L.Linear(1000)\n",
    "        \n",
    "        #계층 연결\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = F.pooling(x, 2, 2)\n",
    "        \n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = F.pooling(x, 2, 2)\n",
    "        \n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = F.pooling(x, 2, 2)\n",
    "        \n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = F.pooling(x, 2, 2)\n",
    "        \n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = F.pooling(x, 2, 2)\n",
    "        \n",
    "        \n",
    "        #합성곱층에서 완전연결층으로 변환하기 위한 reshape\n",
    "        #합성곱층에서는 4차원 텐서를 처리하지만 완전연결계층에서는 2차원 텐서를 처리\n",
    "        #완전연결계층에 데이터를 제공하기 전에 2차원 텐서로 변환\n",
    "        \n",
    "        x = F.reshape(x, (x.shpae[0], -1))\n",
    "        x = F.dropout(F.relu(self.fc6(x)))\n",
    "        x = F.dropout(F.relu(self.fc6(x)))\n",
    "        x = self.fc8(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미 학습된 가중치 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(Model):\n",
    "    WEIGHTS_PATH = 'https://github.com/koki0702/dezero-models/releases/download/v0.1/vgg16.npz'\n",
    "\n",
    "    #여기 pretrained=False\n",
    "    def __init__(self, pretrained=False):\n",
    "        # 이 내용은 위와 같음\n",
    "\n",
    "        #만약 pretrained==True 이면,\n",
    "        #위의 명시된 주소에서 학습된 가중치를 가져와 적용할 수 있도록 한다.\n",
    "        if pretrained:\n",
    "            weights_path = utils.get_file(VGG16.WEIGHTS_PATH)\n",
    "            self.load_weights(weights_path)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = F.pooling(x, 2, 2)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = F.pooling(x, 2, 2)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = F.pooling(x, 2, 2)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = F.pooling(x, 2, 2)\n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = F.pooling(x, 2, 2)\n",
    "        x = F.reshape(x, (x.shape[0], -1))\n",
    "        x = F.dropout(F.relu(self.fc6(x)))\n",
    "        x = F.dropout(F.relu(self.fc7(x)))\n",
    "        x = self.fc8(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess(image, size=(224, 224), dtype=np.float32):\n",
    "        image = image.convert('RGB')\n",
    "        if size:\n",
    "            image = image.resize(size)\n",
    "        image = np.asarray(image, dtype=dtype)\n",
    "        image = image[:, :, ::-1]\n",
    "        image -= np.array([103.939, 116.779, 123.68], dtype=dtype)\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위의 pretrained를 사용하려면 이렇게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dezero.models import VGG16\n",
    "\n",
    "model = VGG16(pretrained=True)\n",
    "\n",
    "x = np.random.randn(1,3,224,224).astype(np.float32)\n",
    "model.plot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 계산그래프로 살펴보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![계산그래프](./Posting3/VGG계산그래프.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.학습된 VGG 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![샘플이미지](./Posting3/샘플이미지투입.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    @staticmethod\n",
    "    def preprocess(image, size=(224, 224), dtype=np.float32):\n",
    "        image = image.convert('RGB')\n",
    "        if size:\n",
    "            image = image.resize(size)\n",
    "        image = np.asarray(image, dtype=dtype)\n",
    "        image = image[:, :, ::-1]\n",
    "        \n",
    "        #이미지넷으로 미리 구해둔 채널의 평균을 이미지에서 빼주는 처리\n",
    "        image -= np.array([103.939, 116.779, 123.68], dtype=dtype)\n",
    "        \n",
    "        #이미지를 RGB -> BGR 순으로 재정렬\n",
    "        #RGB(0,1,2) -> (2,1,0)\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - PIL.Image 형태의 데이터 타입을 dezero에서 다룰 수 있도록 ndarray 타입으로 변경 필요        \n",
    "> - 이 함수를 VGG내부의 preprocess에 적용해두었음.        \n",
    "> - preprocess 함수를 통해 (224,224)크기의 ndarray 타입으로 변환됨을 알 수 있음             \n",
    "> - 또, 미지의 데이터셋을 학습된 가중치에 투입할 수 있도록 VGG에서 사용된 전처리 과정을 정확히 거쳐가도록 처리함(위의 주석 부분)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불러온 이미지 투입시켜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in globals():\n",
    "    import os, sys\n",
    "    sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import dezero\n",
    "from dezero.models import VGG16\n",
    "\n",
    "\n",
    "url = 'https://github.com/oreilly-japan/deep-learning-from-scratch-3/raw/images/zebra.jpg'\n",
    "img_path = dezero.utils.get_file(url)\n",
    "img = Image.open(img_path)\n",
    "\n",
    "x = VGG16.preprocess(img)\n",
    "\n",
    "################ -------------- 여기까지는 동일\n",
    "#배치용 축 추가 \n",
    "#기존의 전처리 마친 데이터는 (3,224,224) -> (1, 3, 224,224)\n",
    "x = x[np.newaxis]\n",
    "\n",
    "model = VGG16(pretrained=True)\n",
    "with dezero.test_mode():\n",
    "    y = model(x)\n",
    "predict_id = np.argmax(y.data)\n",
    "\n",
    "model.plot(x, to_file='vgg.pdf')\n",
    "labels = dezero.datasets.ImageNet.labels()\n",
    "print(labels[predict_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 59 : RNN을 활용한 시계열 데이터 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지금까지의 신경망 : feed-forward(피드포워드)      \n",
    "- 데이터 구조가 한 방향으로, 순방향으로만 데이터를 입력하는 구조        \n",
    "- 순환 신경망\n",
    "\n",
    "![순환신경망 구조](./Posting3/순환신경망.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN계층 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이번 시각의 입력 데이터(시계열 데이터)인 $Xt$ 로,             \n",
    "- 은닉 상태 $ht$를 출력하는 RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rnn식](./Posting3/rnn식.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(Layer):\n",
    "    def __init__(self, hidden_size, in_size=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.x2h = Linear(hidden_size, in_size=in_size)\n",
    "        self.h2h = Linear(hidden_size, in_size=in_size, nobias=True)\n",
    "        self.h = None\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #은닉 상태가 하나도 정해지지 않았다면\n",
    "        #첫투입이므로 x만 이용하여 새로운 은닉벡터 계산\n",
    "        if self.h is None:\n",
    "            h_new = F.tanh(self.x2h(x))\n",
    "            \n",
    "        else:\n",
    "            #위의 rnn식을 통해 이번 층의 입력을 바탕으로 한 새로운 은닉 상태 추출\n",
    "            h_new = F.tanh(self.x2h(x)+ self.h2h(self.h))\n",
    "            self.h = h_new\n",
    "            return h_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Layer):\n",
    "    def __init__(self, out_size, nobias=False, dtype=np.float32, in_size=None):\n",
    "        super().__init__()\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self.W = Parameter(None, name='W')\n",
    "        if self.in_size is not None:\n",
    "            self._init_W()\n",
    "\n",
    "        if nobias:\n",
    "            self.b = None\n",
    "        else:\n",
    "            self.b = Parameter(np.zeros(out_size, dtype=dtype), name='b')\n",
    "\n",
    "    def _init_W(self, xp=np):\n",
    "        I, O = self.in_size, self.out_size\n",
    "        W_data = xp.random.randn(I, O).astype(self.dtype) * np.sqrt(1 / I)\n",
    "        self.W.data = W_data\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.W.data is None:\n",
    "            self.in_size = x.shape[1]\n",
    "            xp = cuda.get_array_module(x)\n",
    "            self._init_W(xp)\n",
    "\n",
    "        y = F.linear(x, self.W, self.b)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN계층에 데이터 주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dezero.layers as L\n",
    "\n",
    "#은닉층 크기만 전달하고, 인풋데이터는 들어오는 사이즈에 따라 그대로 수용하도록 함\n",
    "rnn = L.RNN(10)\n",
    "\n",
    "x = np.random.rand(1,1)\n",
    "h = rnn(x)\n",
    "\n",
    "y = rnn(np.random.rand(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rnn1층](./Posting3/rnn1층.png)        \n",
    "\n",
    "![rnn2층](./Posting3/rnn2층.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dezero import Model\n",
    "import dezero.functions as F\n",
    "import dezero.layers as L\n",
    "\n",
    "class SimpleRNN(Model):\n",
    "    def __init__(self, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        #RNN돌리고\n",
    "        self.rnn = L.RNN(hidden_size)\n",
    "        \n",
    "        #최종출력을 내놓음\n",
    "        self.fc = L.Linear(out_size)\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.rnn.reset_state()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.rnn(x)\n",
    "        y = self.fc(h)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 심플 RNN모델 학습시켜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1,1 사이즈에 맞게 random을 만들어줌\n",
    "seq_data = [np.random.randn(1,1) for _ in range(1000)]\n",
    "\n",
    "xs = seq_data[0:1]\n",
    "ts = seq_data[1:]\n",
    "\n",
    "model = SimpleRNN(10,1)\n",
    "\n",
    "loss, cnt = 0,0\n",
    "\n",
    "for x, t in zip(xs, ts):\n",
    "    y = model(x)\n",
    "    loss += F.mean_squared_error(y, t)\n",
    "    \n",
    "    cnt += 1\n",
    "    \n",
    "    #Truncated BPTT, 2개째에서 끊어줌\n",
    "    #이전의 은닉 상태를 유지해야 한다는 점이 중요!\n",
    "    if cnt == 2:\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![손실함수이후의그래프](./Posting3/전체모습.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 역전파에서 끊어주되      \n",
    "> RNN의 은닉 상태가 유지된다는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![트룬케이트](./Posting3/truncated.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연결을 끊어주는 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    \n",
    "    def unchain(self):\n",
    "        self.creator = None\n",
    "        \n",
    "    #마주치는 모든 변수들의 creator를 none으로    \n",
    "    def unchained_backward(self):\n",
    "        \n",
    "        #아직 끊어지지 않은 연결에 대해서는 끊어내기 위해\n",
    "        if self.creator is not None:\n",
    "            funcs = [self.creator]\n",
    "            \n",
    "            while funcs:\n",
    "                \n",
    "                #가장 최근의 함수를 꺼내서\n",
    "                f = funcs.pop()\n",
    "                \n",
    "                #그 변수를 꺼내서\n",
    "                for x in f.inputs:\n",
    "                    \n",
    "                    #그 인풋의 체인을 끊어준다.\n",
    "                    if x.creator is not None:\n",
    "                        funcs.append(x.creator)\n",
    "                        x.unchain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기존에 변수-함수-변수를 연결해주던 creator 를 None으로 설정하여 끊어주는 역할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사인파 예측(RNN테스트)        \n",
    "\n",
    "- 시퀀셜한 사인그래프를 예측해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinCurve(Dataset):\n",
    "\n",
    "    def prepare(self):\n",
    "        num_data = 1000\n",
    "        dtype = np.float64\n",
    "\n",
    "        x = np.linspace(0, 2 * np.pi, num_data)\n",
    "        noise_range = (-0.05, 0.05)\n",
    "        noise = np.random.uniform(noise_range[0], noise_range[1], size=x.shape)\n",
    "        if self.train:\n",
    "            y = np.sin(x) + noise\n",
    "        else:\n",
    "            y = np.cos(x)\n",
    "        y = y.astype(dtype)\n",
    "        self.data = y[:-1][:, np.newaxis]\n",
    "        self.label = y[1:][:, np.newaxis]\n",
    "\n",
    "        \n",
    "import numpy as np\n",
    "import dezero\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_set = dezero.datasets.SinCurve(train=True)\n",
    "\n",
    "print(len(train_set))\n",
    "print(train_set[0])\n",
    "print(train_set[1])\n",
    "print(train_set[2])\n",
    "\n",
    "xs = [example[0] for example in train_set]\n",
    "\n",
    "#1이어야 하지 않나?\n",
    "ts = [example[1] for example in train_set]\n",
    "\n",
    "plt.plot(np.arrange(len(xs)), xs, label='xs')\n",
    "plt.plot(np.arrange(len(ts)), ts, label='ts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![노이즈가있는](./Posting3/노이즈가있는.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dezero\n",
    "from dezero import Model\n",
    "import dezero.functions as F\n",
    "import dezero.layers as L\n",
    "\n",
    "#하이퍼 파라미터 설정\n",
    "max_epoch = 100\n",
    "hidden_size = 100\n",
    "\n",
    "#bptt길이\n",
    "bptt_length = 30\n",
    "\n",
    "train_set = dezero.datasets.SinCurve(train=True)\n",
    "\n",
    "#시퀀셜 데이터 길이 == 트레인 셋 길이\n",
    "seqlen = len(train_set)\n",
    "\n",
    "\n",
    "class SimpleRNN(Model):\n",
    "    def __init__(self, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        self.rnn = L.RNN(hidden_size)\n",
    "        self.fc = L.Linear(out_size)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.rnn.reset_state()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = self.rnn(x)\n",
    "        y = self.fc(h)\n",
    "        return y\n",
    "\n",
    "\n",
    "model = SimpleRNN(hidden_size, 1)\n",
    "optimizer = dezero.optimizers.Adam().setup(model)\n",
    "\n",
    "#트레이닝 시작\n",
    "for epoch in range(max_epoch):\n",
    "    \n",
    "    #처음의 상태및 loss, count(bptt세기 위한 변수)를 0로 초기화\n",
    "    model.reset_state()\n",
    "    loss, count = 0, 0\n",
    "\n",
    "    \n",
    "    for x, t in train_set:\n",
    "        \n",
    "        #학습을 위해 모델에 투입될 x의 형태를 리셰이프\n",
    "        #dezero에서는 입력 데이터가 2차원/4차원 텐서만 가능\n",
    "        x = x.reshape(1, 1)\n",
    "        y = model(x)\n",
    "        loss += F.mean_squared_error(y, t)\n",
    "        count += 1\n",
    "\n",
    "        #에포크가 미리 지정해둔 bptt의 길이와 일치하거나, 모든 데이터셋 학습이 끊나면 unchain()\n",
    "        if count % bptt_length == 0 or count == seqlen:\n",
    "            model.cleargrads()\n",
    "            loss.backward()\n",
    "            loss.unchain_backward()\n",
    "            optimizer.update()\n",
    "\n",
    "    avg_loss = float(loss.data) / count\n",
    "    print('| epoch %d | loss %f' % (epoch + 1, avg_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트를 위해 코사인 예측시켜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "#리얼 코사인\n",
    "#np.lineapce(start, stop, num)\n",
    "xs = np.cos(np.linspace(0, 4 * np.pi, 1000))\n",
    "model.reset_state()\n",
    "pred_list = []\n",
    "\n",
    "with dezero.no_grad():\n",
    "    for x in xs:\n",
    "        x = np.array(x).reshape(1, 1)\n",
    "        y = model(x)\n",
    "        pred_list.append(float(y.data))\n",
    "\n",
    "plt.plot(np.arange(len(xs)), xs, label='y=cos(x)')\n",
    "plt.plot(np.arange(len(xs)), pred_list, label='predict')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 60 : LSTM과 데이터 로더"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__두가지 개선 포인트__         \n",
    "\n",
    "##### 1. 시계열 데이터용 '데이터 로더' 만들기        \n",
    "- 모델에 데이터를 1개씩 전달하여(for x in range(train_data):) 이용하였는데, 이를 개선     \n",
    "- 시계열 데이터용 데이터 로더를 만들어, 미니배치 단위로 데이터를 전달할 수 있도록 구현 개선     \n",
    "\n",
    "##### 2. RNN 대신 LSTM 계층을 이용함         \n",
    "- 더 나은 인식 성능\n",
    "\n",
    "\n",
    "\n",
    "###### 이후 사인파 학습을 다시 한 번 시도해보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시계열 데이터용 데이터 로더 만들기     \n",
    "\n",
    "- 미니배치 단위로 처리하려면, 커다란 하나의 데이터셋을 미니배치 단위로 다르게 지정해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, batch_size, gpu=False):\n",
    "        super()__init__(dataset=dataset, batch_size=batch_size, shuffle=False, gpu=gpu)\n",
    "        \n",
    "    def __next__(self):\n",
    "        \n",
    "        #만약 최대 수가 되면 멈추기!\n",
    "        if self.iteration >= self.max_iter:\n",
    "            self.reset()\n",
    "            raise StopIteration\n",
    "            \n",
    "        #나누어 몫을 jump로 기억\n",
    "        jump = self.data_size//self.batch_size\n",
    "        \n",
    "        #배치 인덱스 = [새로 시작하는 인덱스]\n",
    "        #이번 점프 + 나머지(self.iteration % self.data_size)\n",
    "        batch_index = [(i*jump) + self.iteration % self.data_size for i in range(self.batch_size)] \n",
    "        \n",
    "        batch = [self.dataset[i] for i in batch_index]\n",
    "        \n",
    "        xp = cuda.cupy if self.gpu else np\n",
    "        x = [example[0] for example in batch]\n",
    "        t = [example[1] for example in batch]\n",
    "        \n",
    "        self.iteration += 1\n",
    "        \n",
    "        return x, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 적용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dezero.datasets.SinCurve(train=True)\n",
    "dataloader = SeqDataLoader(train_set, batch_size=3)\n",
    "\n",
    "x, t = next(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM 계층 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LSTM](./Posting3/LSTM1.png)\n",
    "\n",
    "![LSTM](./Posting3/LSTM2.png)\n",
    "\n",
    "![LSTM](./Posting3/LSTM3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(Layer):\n",
    "    def __init__(self, hidden_size, in_size=None):\n",
    "        super().__init__()\n",
    "\n",
    "        H, I = hidden_size, in_size\n",
    "        self.x2f = Linear(H, in_size=I)\n",
    "        self.x2i = Linear(H, in_size=I)\n",
    "        self.x2o = Linear(H, in_size=I)\n",
    "        self.x2u = Linear(H, in_size=I)\n",
    "        self.h2f = Linear(H, in_size=H, nobias=True)\n",
    "        self.h2i = Linear(H, in_size=H, nobias=True)\n",
    "        self.h2o = Linear(H, in_size=H, nobias=True)\n",
    "        self.h2u = Linear(H, in_size=H, nobias=True)\n",
    "        self.reset_state()\n",
    "\n",
    "        #기억셀 c, 은닉벡터 h\n",
    "    def reset_state(self):\n",
    "        self.h = None\n",
    "        self.c = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        #첫 시도\n",
    "        if self.h is None:\n",
    "            f = F.sigmoid(self.x2f(x))\n",
    "            i = F.sigmoid(self.x2i(x))\n",
    "            o = F.sigmoid(self.x2o(x))\n",
    "            u = F.tanh(self.x2u(x))\n",
    "        else:\n",
    "            f = F.sigmoid(self.x2f(x) + self.h2f(self.h))\n",
    "            i = F.sigmoid(self.x2i(x) + self.h2i(self.h))\n",
    "            o = F.sigmoid(self.x2o(x) + self.h2o(self.h))\n",
    "            u = F.tanh(self.x2u(x) + self.h2u(self.h))\n",
    "\n",
    "            #기억셀이 없을 경우(첫 트라이)\n",
    "        if self.c is None:\n",
    "            c_new = (i * u)\n",
    "        else:\n",
    "            c_new = (f * self.c) + (i * u)\n",
    "\n",
    "        h_new = o * F.tanh(c_new)\n",
    "\n",
    "        self.h, self.c = h_new, c_new\n",
    "        return h_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM로 sin학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dezero\n",
    "from dezero import Model\n",
    "from dezero import SeqDataLoader\n",
    "import dezero.functions as F\n",
    "import dezero.layers as L\n",
    "\n",
    "\n",
    "max_epoch = 100\n",
    "batch_size = 30\n",
    "hidden_size = 100\n",
    "bptt_length = 30\n",
    "\n",
    "#==============================================================\n",
    "#개선 1:시계열 데이터 로더 적용\n",
    "train_set = dezero.datasets.SinCurve(train=True)\n",
    "dataloader = SeqDataLoader(train_set, batch_size=batch_size)\n",
    "seqlen = len(train_set)\n",
    "\n",
    "\n",
    "class BetterRNN(Model):\n",
    "    def __init__(self, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        #==================================\n",
    "        #개선 2: LSTM층 사용\n",
    "        self.rnn = L.LSTM(hidden_size)\n",
    "        self.fc = L.Linear(out_size)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.rnn.reset_state()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        y = self.rnn(x)\n",
    "        y = self.fc(y)\n",
    "        return y\n",
    "\n",
    "model = BetterRNN(hidden_size, 1)\n",
    "optimizer = dezero.optimizers.Adam().setup(model)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    model.reset_state()\n",
    "    loss, count = 0, 0\n",
    "\n",
    "    for x, t in dataloader:\n",
    "        y = model(x)\n",
    "        loss += F.mean_squared_error(y, t)\n",
    "        count += 1\n",
    "\n",
    "        if count % bptt_length == 0 or count == seqlen:\n",
    "            model.cleargrads()\n",
    "            loss.backward()\n",
    "            loss.unchain_backward()\n",
    "            optimizer.update()\n",
    "    avg_loss = float(loss.data) / count\n",
    "    print('| epoch %d | loss %f' % (epoch + 1, avg_loss))\n",
    "\n",
    "# Plot\n",
    "xs = np.cos(np.linspace(0, 4 * np.pi, 1000))\n",
    "model.reset_state()\n",
    "pred_list = []\n",
    "\n",
    "with dezero.no_grad():\n",
    "    for x in xs:\n",
    "        x = np.array(x).reshape(1, 1)\n",
    "        y = model(x)\n",
    "        pred_list.append(float(y.data))\n",
    "\n",
    "plt.plot(np.arange(len(xs)), xs, label='y=cos(x)')\n",
    "plt.plot(np.arange(len(xs)), pred_list, label='predict')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 칼럼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 함수와 계층 추가             \n",
    "\n",
    "- 텐서 곱을 해주는 tensorDot         \n",
    "- 배치 정규화를 해주는 batchNorm    \n",
    "\n",
    "\n",
    "#### 2. 메모리 사용 효율 개선          \n",
    "\n",
    "- 딥러닝 프레임워크는 메모리의 효율적인 사용량도 중요한 토픽     \n",
    "- esp, 대규모 신경망은 메모리를 많이 사용하기 때문에 데이터를 물리적인 메모리에 다 담지 못하는 문제가 흔히 발생함\n",
    "\n",
    "- 현재는 순전파시의 계산 결과를 모두 기억해놓도록 설계했지만\n",
    "- tanh의 경우, 순전파가 없이도 역전파를 계산 가능하므로($1-y^2$) 이를 취사선택할 수 있도록 확장하는 등\n",
    "\n",
    "- [Aggressive Buffer Release](https://docs.google.com/document/d/1CxNS2xg2bLT9LoUe6rPSMuIuqt8Gbkz156LTPJPT3BE/edit#)   \n",
    "\n",
    "- Abstract\n",
    "This is a proposal to reduce the memory consumption of the computational graph built for backprop. The reduction is achieved by dropping arrays that are not needed for the backward method of each function node. It requires restructuring the graph definition, and thus it requires a slight modification to the API. \n",
    "\n",
    "(이 제안은 백프로파게이션에서의 메모리 소비를 감소시키도록 하는 제안이다. 이 reduction은 역전파 시 필요하지 않은 array를 제외(drop)함으로써 이루어진다. 해당 연산을 위해서는 그래프 정의를 재구축해야 하며, API에 다소의 변경이 필요하다.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 정적 계산 그래프와 ONNX 지원     \n",
    "\n",
    "- 현재 define-by-Run(동적) 방식으로 고안되어 있으므로, 이를 Define-and-Run(정적) 방식으로도 확대     \n",
    "- ONNX 라는 데이터 포맷을 지원\n",
    "\n",
    "[ONNX깃허브](https://github.com/onnx/onnx)\n",
    "\n",
    "- Open Neural Network Exchange (ONNX) is an open ecosystem that empowers AI developers to choose the right tools as their project evolves. ONNX provides an open source format for AI models, both deep learning and traditional ML. It defines an extensible computation graph model, as well as definitions of built-in operators and standard data types. Currently we focus on the capabilities needed for inferencing (scoring).\n",
    "(ONNX는 AI모델, deep learning 및 traditional ml모델을 위한 오픈소스 포맷을 제공한다. ONNX는 computational graph, 빌트-인 오퍼레이터 및 표준 데이터 타입을 확장 가능하도록 정의한다.)\n",
    "\n",
    "- ONNX를 사용하면 기학습된 모델을 다른 프레임워크로 쉽게 이식할 수 있다.\n",
    "\n",
    "ONNX is widely supported and can be found in many frameworks, tools, and hardware. Enabling interoperability between different frameworks and streamlining the path from research to production helps increase the speed of innovation in the AI community. We invite the community to join us and further evolve ONNX.\n",
    "\n",
    "\n",
    "### 4. PyPI 에 공개     \n",
    "- 파이썬 패키지로써 PyPI에 공개     \n",
    "\n",
    "### 5. API 문서 준비        \n",
    "- 사용자를 위한 가이드 문서 준비       \n",
    "- docstring    \n",
    "- Sphinx를 이용하여 PDF, HTML 형태로 API 문서 뽑아내기 [사용법](https://tech.ssut.me/start-python-documentation-using-sphinx/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그외, 로고 준비 및 구현 예 추가(+GAN, VAE, Style Transfer 등..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.구글 코랩에서 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[이 링크로 들어간다면!](https://colab.research.google.com/github/WegraLee/deep-learning-from-scratch-3/blob/master/examples/mnist_colab_gpu.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
